{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate feature vector from inception_v4 model using TF_exractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setpath(path):\n",
    "    os.chdir(path)\n",
    "    print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index(name):\n",
    "    name = str(name)\n",
    "    p_s = re.compile(\"[0-9]+.jpeg\")\n",
    "    p_e = re.compile(\".jpeg\")\n",
    "\n",
    "    m_s = p_s.search(name)\n",
    "    m_e = p_e.search(name)\n",
    "\n",
    "    return name[m_s.start():m_e.start()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/haewonpark/Projects/handson/TF_FeatureExtraction\n"
     ]
    }
   ],
   "source": [
    "username='haewonpark'\n",
    "path_features = '/Users/'+username+'/Projects/handson/TF_FeatureExtraction/'\n",
    "setpath(path_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/\"+username+\"/Projects/handson/models/research/slim\")\n",
    "import nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoints/inception_v4.ckpt\n",
      "Conv2d_1a_3x3 has shape (?, 149, 149, 32)\n",
      "Conv2d_2a_3x3 has shape (?, 147, 147, 32)\n",
      "Conv2d_2b_3x3 has shape (?, 147, 147, 64)\n",
      "Mixed_3a has shape (?, 73, 73, 160)\n",
      "Mixed_4a has shape (?, 71, 71, 192)\n",
      "Mixed_5a has shape (?, 35, 35, 384)\n",
      "Mixed_5b has shape (?, 35, 35, 384)\n",
      "Mixed_5c has shape (?, 35, 35, 384)\n",
      "Mixed_5d has shape (?, 35, 35, 384)\n",
      "Mixed_5e has shape (?, 35, 35, 384)\n",
      "Mixed_6a has shape (?, 17, 17, 1024)\n",
      "Mixed_6b has shape (?, 17, 17, 1024)\n",
      "Mixed_6c has shape (?, 17, 17, 1024)\n",
      "Mixed_6d has shape (?, 17, 17, 1024)\n",
      "Mixed_6e has shape (?, 17, 17, 1024)\n",
      "Mixed_6f has shape (?, 17, 17, 1024)\n",
      "Mixed_6g has shape (?, 17, 17, 1024)\n",
      "Mixed_6h has shape (?, 17, 17, 1024)\n",
      "Mixed_7a has shape (?, 8, 8, 1536)\n",
      "Mixed_7b has shape (?, 8, 8, 1536)\n",
      "Mixed_7c has shape (?, 8, 8, 1536)\n",
      "Mixed_7d has shape (?, 8, 8, 1536)\n",
      "AuxLogits has shape (?, 1001)\n",
      "global_pool has shape (?, 1, 1, 1536)\n",
      "PreLogitsFlatten has shape (?, 1536)\n",
      "Logits has shape (?, 1001)\n",
      "Predictions has shape (?, 1001)\n",
      "################################################################################\n",
      "Batch Size: 64\n",
      "Number of Examples: 697\n",
      "Number of Batches: 11\n",
      "Extracting features for layer 'AuxLogits' with shape [704, 1001]\n",
      "Extracting features for layer 'global_pool' with shape [704, 1, 1, 1536]\n",
      "Extracting features for layer 'PreLogitsFlatten' with shape [704, 1536]\n",
      "Extracting features for layer 'Logits' with shape [704, 1001]\n",
      "################################################################################\n",
      "[2018-07-17 15:11] Batch 0001/0011, Batch Size = 64, Examples in Queue = 690, Examples/Sec = 1.61\n",
      "[2018-07-17 15:11] Batch 0002/0011, Batch Size = 64, Examples in Queue = 606, Examples/Sec = 1.71\n",
      "[2018-07-17 15:12] Batch 0003/0011, Batch Size = 64, Examples in Queue = 542, Examples/Sec = 1.78\n",
      "[2018-07-17 15:13] Batch 0004/0011, Batch Size = 64, Examples in Queue = 478, Examples/Sec = 1.75\n",
      "[2018-07-17 15:13] Batch 0005/0011, Batch Size = 64, Examples in Queue = 414, Examples/Sec = 1.77\n",
      "[2018-07-17 15:14] Batch 0006/0011, Batch Size = 64, Examples in Queue = 350, Examples/Sec = 1.79\n",
      "[2018-07-17 15:14] Batch 0007/0011, Batch Size = 64, Examples in Queue = 286, Examples/Sec = 1.78\n",
      "[2018-07-17 15:15] Batch 0008/0011, Batch Size = 64, Examples in Queue = 222, Examples/Sec = 1.73\n",
      "[2018-07-17 15:16] Batch 0009/0011, Batch Size = 64, Examples in Queue = 158, Examples/Sec = 1.79\n",
      "[2018-07-17 15:16] Batch 0010/0011, Batch Size = 64, Examples in Queue = 94, Examples/Sec = 1.70\n",
      "[2018-07-17 15:17] Batch 0011/0011, Batch Size = 64, Examples in Queue = 30, Examples/Sec = 1.56\n",
      "Successfully written features to: ./FV_inceptionV4.h5\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "%run example_feat_extract.py --network inception_v4 --checkpoint ./checkpoints/inception_v4.ckpt --image_path ./images/ --out_file ./FV_inceptionV4.h5 --layer_names AuxLogits,global_pool,PreLogitsFlatten,Logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading feacture vectors...\n",
      "Available feature layer : ['AuxLogits', 'Logits', 'PreLogitsFlatten', 'filenames', 'global_pool']\n",
      "==========================================================================================\n",
      "Selected layer :  AuxLogits\n",
      "# of images :  697 , # of features :  1001\n",
      "min feature value: -5.8775845 , max feature value:  11.935148\n"
     ]
    }
   ],
   "source": [
    "# Load feature vector .h5 file \n",
    "\n",
    "features = h5py.File('./FV_inceptionV4.h5', 'r')\n",
    "print(\"Loading feacture vectors...\")\n",
    "\n",
    "features_key = list(features.keys())\n",
    "print(\"Available feature layer :\", features_key)\n",
    "\n",
    "# get feature vector at a layer\n",
    "layer = 'AuxLogits'\n",
    "print(\"===\"*30)\n",
    "print(\"Selected layer : \", layer)\n",
    "\n",
    "features_value = features[layer][...]\n",
    "a = np.array(features_value)\n",
    "features_value = np.reshape(a, (a.shape[0], -1)) #depth가 1보다 클 때 depth 1의 벡터로 전환\n",
    "\n",
    "features_filename = features['filenames'][...]\n",
    "features_index = list(map(get_index, features_filename))\n",
    "\n",
    "feat_cols = ['feature' + str(i) for i in range(features_value.shape[1])]\n",
    "df = pd.DataFrame(features_value, columns = feat_cols)\n",
    "df['index'] = features_index\n",
    "\n",
    "print(\"# of images : \", df.shape[0], \", # of features : \", len(feat_cols))\n",
    "\n",
    "min_value = np.amin(df[feat_cols].values)\n",
    "max_value = np.amax(df[feat_cols].values)\n",
    "print(\"min feature value:\", min_value, \", max feature value: \", max_value)\n",
    "\n",
    "#df[feat_cols] = df[feat_cols] - np.amin(df[feat_cols].values)\n",
    "#print(\"min :\", np.amin(df[feat_cols].values), \"max : \", np.max(df[feat_cols].values))\n",
    "#df[feat_cols] = df[feat_cols] / 10\n",
    "#print(\"min :\", np.amin(df[feat_cols].values), \"max : \", np.max(df[feat_cols].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature0</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature992</th>\n",
       "      <th>feature993</th>\n",
       "      <th>feature994</th>\n",
       "      <th>feature995</th>\n",
       "      <th>feature996</th>\n",
       "      <th>feature997</th>\n",
       "      <th>feature998</th>\n",
       "      <th>feature999</th>\n",
       "      <th>feature1000</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 1002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [feature0, feature1, feature2, feature3, feature4, feature5, feature6, feature7, feature8, feature9, feature10, feature11, feature12, feature13, feature14, feature15, feature16, feature17, feature18, feature19, feature20, feature21, feature22, feature23, feature24, feature25, feature26, feature27, feature28, feature29, feature30, feature31, feature32, feature33, feature34, feature35, feature36, feature37, feature38, feature39, feature40, feature41, feature42, feature43, feature44, feature45, feature46, feature47, feature48, feature49, feature50, feature51, feature52, feature53, feature54, feature55, feature56, feature57, feature58, feature59, feature60, feature61, feature62, feature63, feature64, feature65, feature66, feature67, feature68, feature69, feature70, feature71, feature72, feature73, feature74, feature75, feature76, feature77, feature78, feature79, feature80, feature81, feature82, feature83, feature84, feature85, feature86, feature87, feature88, feature89, feature90, feature91, feature92, feature93, feature94, feature95, feature96, feature97, feature98, feature99, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 1002 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check is any null value in dataframe\n",
    "df[df.isnull().T.any().T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
